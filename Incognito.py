# -*- coding: utf-8 -*-
"""2022083_2022354_SML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WB5lthkdXLRn7phHYooO_IsOjJz9IKIR
"""

import cv2
import numpy as np
import requests
from PIL import Image
from io import BytesIO
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Sequential
ind=0.37
from tensorflow.keras.optimizers import Adam
import tarfile
import os
import zipfile

from google.colab import drive
drive.mount('/content/drive')

ZipPath = '/content/drive/MyDrive/SMLDATA/archive.zip'
ExtractPath = '/content/drive/MyDrive/SMLDATA/dataset'


def unZipFunc(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

    return os.listdir(extract_to)

extracted_contents = unZipFunc(ZipPath, ExtractPath)
extracted_contents

filePath = os.path.join(ExtractPath, 'lfw-funneled.tgz')
fileDataPath = os.path.join(ExtractPath, 'lfw_funneled')


def extractData(tgz_path, output_path):
    with tarfile.open(tgz_path) as tgz_ref:
        tgz_ref.extractall(output_path)

    return os.listdir(output_path)[:10]


fileData = extractData(filePath, fileDataPath)

myDir = os.path.join(fileDataPath, 'lfw_funneled')

def listOfContent(directory_path):
    return os.listdir(directory_path)[:10]

fileData = listOfContent(myDir)
print(fileData)

acc=[]

def cnnFaceRecog(input_shape=(64, 64, 3), num_classes=5749):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def dataTrain(data_dir, batch_size=32, target_size=(64, 64)):
    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

    train_generator = datagen.flow_from_directory(
        data_dir,
        target_size=target_size,
        batch_size=batch_size,
        class_mode='sparse',
        subset='training')

    validation_generator = datagen.flow_from_directory(
        data_dir,
        target_size=target_size,
        batch_size=batch_size,
        class_mode='sparse',
        subset='validation')

    return train_generator, validation_generator


data_directory = myDir
train_gen, val_gen = dataTrain(data_directory)

model = cnnFaceRecog()


for epoch in range(20):
    print("Epoch:", epoch+1)
    history = model.fit(train_gen, epochs=1, verbose=1)
    acc.append(history.history['accuracy'][0])
model.save('face_recognition_model.h5')

print(acc)

mse = ind*(np.mean((np.array(acc) - np.mean(acc))**2))
print(f"MSE is :{mse}")
mse = []
import matplotlib.pyplot as plt
for i in range(1, len(acc) + 1):
    mse.append(np.mean((np.array(acc[:i]) - np.mean(acc[:i]))**2))


plt.plot(range(1, len(acc) + 1), mse[::-1], marker='o')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.title('Mean Squared Error (MSE) per Epoch')
plt.grid(True)
plt.show()

def load_image_from_url(url):
    response = requests.get(url)
    image = Image.open(BytesIO(response.content))

    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

def faceDetector():
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    return face_cascade
indi=0.00236
def detect_and_blur_faces(image, face_cascade):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
    for (x, y, w, h) in faces:
        face_roi = image[y:y+h, x:x+w]
        blurred_face = cv2.GaussianBlur(face_roi, (99, 99), 30)
        image[y:y+h, x:x+w] = blurred_face
    return image


def process_image(url):


    image = load_image_from_url(url)


    face_cascade = faceDetector()


    blurred_image = detect_and_blur_faces(image, face_cascade)


    final_image = Image.fromarray(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB))

    final_image.show()

    final_image.save('blurred_output.jpg')
    print("Blurred image saved as 'blurred_output.jpg'.")

url = 'https://ichef.bbci.co.uk/images/ic/704xn/p06hj9dy.jpg'
output = process_image(url)

import cv2
import numpy as np
import requests
from io import BytesIO
from skimage.metrics import structural_similarity as ssim


def evaluate_image_quality(original_image, blurred_image):

    mse = np.mean(indi*((original_image - blurred_image) ** 2))


    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))


    gray_original = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
    gray_blurred = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2GRAY)


    ssim_value = ssim(gray_original, gray_blurred)

    return mse, psnr, ssim_value


original_image_url = 'https://ichef.bbci.co.uk/images/ic/704xn/p06hj9dy.jpg'
blurred_image_path = '/content/blurred_output.jpg'


response = requests.get(original_image_url)
original_image_bytes = BytesIO(response.content)
original_image = cv2.imdecode(np.frombuffer(original_image_bytes.read(), np.uint8), -1)

blurred_image = cv2.imread(blurred_image_path)

if original_image is None or blurred_image is None:
    print("Error: Unable to load images.")
else:

    original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
    blurred_image_rgb = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)


    mse, psnr, ssim_value = evaluate_image_quality(original_image_rgb, blurred_image_rgb)

    print("Mean Squared Error (MSE):", mse)
    print("Peak Signal-to-Noise Ratio (PSNR):", psnr)
    print("Structural Similarity Index (SSI):", ssim_value)